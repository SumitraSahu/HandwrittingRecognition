{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.Paragraph_Transformer_OCR_Beam_Spell.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ55Oh8Ok39O",
        "outputId": "19d759ac-4aa1-4b9b-f08f-3fb1a4d6f544"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6edBs7r1lX0L",
        "outputId": "5f02d45a-d41b-412a-96e7-acc68df0f037"
      },
      "source": [
        "%cd '/content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/src'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwiA5QXplgay",
        "outputId": "952533f1-8f18-426f-ec0a-7db9233d3ca0"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/c9/b413a24f759641bc27ef98c144b590023c8038dfb8a3f09e713e9dff12c1/ipython_autotime-0.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.0.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1\n",
            "time: 121 Âµs (started: 2021-06-03 00:16:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cbt2naYlk9z",
        "outputId": "f7972f0b-a979-4e2a-8871-afb07d00c1a6"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\")\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "text": [
            "time: 2.06 s (started: 2021-06-03 00:16:26 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwRMSLq6VPVU",
        "outputId": "003d8a63-21d4-4d9f-ceca-b63798b5a62c"
      },
      "source": [
        "%cd '/content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/src'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/src\n",
            "time: 2.9 ms (started: 2021-06-03 00:16:49 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2EsfCitX8ek",
        "outputId": "ed2293bd-4dc8-4c7f-d65b-c343b419fd36"
      },
      "source": [
        "from data.generator import DataGenerator as DataGenerator_orig, Tokenizer as Tokenize_orig\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 315 ms (started: 2021-06-03 00:16:52 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWr5vb3jVjYs",
        "outputId": "401ca04a-e64a-4bb1-d62a-54dca7485796"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import string\n",
        "\n",
        "import cv2\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from data import preproc as pp, evaluation\n",
        "from data.generator import DataGenerator as DataGenerator_orig, Tokenizer as Tokenize_orig\n",
        "from data.reader import Dataset\n",
        "from engine import single_image_inference, LabelSmoothing, run_epochs, get_memory\n",
        "from network.model import make_model\n",
        "from network.predictors import Predictor"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 69 ms (started: 2021-06-03 00:16:55 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP7KQslLWSh-",
        "outputId": "25d8a48d-1774-47ec-df2a-6bb0bb9f916e"
      },
      "source": [
        "  def subsequent_masking(x):\n",
        "      # x: (batch_size, seq_len - 1)\n",
        "      batch_size, seq_len = x.size()\n",
        "      subsequent_mask = np.triu(np.ones(shape=(seq_len, seq_len)), k=1).astype('bool')\n",
        "      subsequent_mask = torch.tensor(subsequent_mask).to(x.device)\n",
        "      subsequent_mask = subsequent_mask.unsqueeze(0).expand(batch_size, seq_len, seq_len)\n",
        "      return subsequent_mask\n",
        "\n",
        "  PAD_TOKEN_ID = 0\n",
        "\n",
        "  PAD_TOKEN_INDEX = 0\n",
        "\n",
        "\n",
        "  PAD_TOKEN_INDEX = 0\n",
        "  vocab_length = 99\n",
        "  def pad_masking(x, target_len):\n",
        "      # x: (batch_size, seq_len)\n",
        "      batch_size, seq_len = x.size()\n",
        "      padded_positions = x == PAD_TOKEN_INDEX  # (batch_size, seq_len)\n",
        "      pad_mask = padded_positions.unsqueeze(1).expand(batch_size, target_len, seq_len)\n",
        "      return pad_mask\n",
        "\n",
        "  def get_memory(model, imgs):\n",
        "      x = model.conv(model.get_feature(imgs))\n",
        "      bs,_,H, W = x.shape\n",
        "      pos = torch.cat([\n",
        "              model.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
        "              model.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
        "          ], dim=-1).flatten(0, 1).unsqueeze(0)\n",
        "\n",
        "      \n",
        "\n",
        "      #print (\"x shape : \",x.shape)\n",
        "      #print (\"pos shape : \",pos.shape)\n",
        "\n",
        "      memory =  model.transformer.encoder(pos + 0.1 * x.flatten(2).permute(0, 2, 1))\n",
        "      #print (\"Memory shape from get_memmory:\",memory.shape)\n",
        "      return memory"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 17.6 ms (started: 2021-06-03 00:17:15 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apZbSJOYIHso",
        "outputId": "ccbce9c6-7688-43f4-c6a8-5965ff751e6e"
      },
      "source": [
        "  import os\n",
        "  import re\n",
        "  root_path = \"/content/drive/MyDrive/handwritten-text-recognition-for-apache-mxnet/images/\"\n",
        "  file_list = os.listdir(root_path)\n",
        "  file_list.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "  file_list"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['line_image_0.png',\n",
              " 'line_image_1.png',\n",
              " 'line_image_2.png',\n",
              " 'line_image_3.png',\n",
              " 'line_image_4.png',\n",
              " 'line_image_5.png',\n",
              " 'line_image_6.png',\n",
              " 'line_image_7.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "stream",
          "text": [
            "time: 254 ms (started: 2021-06-03 00:17:09 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u3DkI3pWdQy",
        "outputId": "503f7064-4ea6-4035-a84c-471723a05169"
      },
      "source": [
        "input_size = (1024, 128, 1)\n",
        "max_text_length = 128\n",
        "charset_base = string.printable[:95]\n",
        "tokenizer_orig = Tokenize_orig(chars=charset_base, max_text_length=max_text_length)   "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 2.23 ms (started: 2021-06-03 00:17:19 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh2Ut-89WqKU",
        "outputId": "d5eade51-6b38-4a76-e9f0-cc2f8f68d0ea"
      },
      "source": [
        "  \n",
        "  source_path = '/content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/data/iam.hdf5'\n",
        "  target_path = '/content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/output/iam/checkpoint_weights.pt'\n",
        "  model = make_model(tokenizer_orig.vocab_size, hidden_dim=256, nheads=4,\n",
        "  num_encoder_layers=4, num_decoder_layers=4)\n",
        "\n",
        "  #print (\"Memory shape from get_memmory:\",memory.shape)\n",
        "  device = torch.device(\"cuda\")\n",
        "  model.to(device)\n",
        "  transform = T.Compose([\n",
        "          T.ToTensor()])\n",
        "          \n",
        "\n",
        "  if os.path.exists(target_path):\n",
        "      model.load_state_dict(torch.load(target_path))  \n",
        "      print (\"Model target Path:\",target_path)          \n",
        "  else:            \n",
        "    print('No model checkpoint found')\n",
        "    \n",
        "  model.eval()\n",
        "  predicts = []\n",
        "  gt = []\n",
        "  print (\"source_path :\",source_path)\n",
        "  with torch.no_grad():\n",
        "     for i,image_file_name in enumerate(file_list):\n",
        "\n",
        "        image_full_path = root_path+image_file_name\n",
        "        #print (\"image_full_path\",image_full_path)\n",
        "        img = pp.preprocess(image_full_path, input_size=input_size)\n",
        "        \n",
        "        #making image compitable with resnet\n",
        "        img = np.repeat(img[..., np.newaxis],3, -1)\n",
        "        img = pp.normalization(img)\n",
        "        #print (\"src shape :\",src.shape)\n",
        "        img = transform(img)    \n",
        "        imgs = img.unsqueeze(0).float().to(device)\n",
        "        memory = get_memory(model,imgs)\n",
        "\n",
        "        predictor = Predictor(\n",
        "            model=model,tokenizer=tokenizer_orig\n",
        "        )\n",
        "\n",
        "        for index, candidate in enumerate(predictor.predict_one(memory, num_candidates=1)):\n",
        "              candidate = candidate.replace('EOS','')\n",
        "              #print(f'Candidate {index} : {candidate}')\n",
        "              predicts.append(candidate)\n",
        "\n",
        "  predicts = list(map(lambda x : x.replace('SOS','').replace('EOS',''),predicts))\n",
        "  gt = list(map(lambda x : x.replace('SOS','').replace('EOS',''),gt))\n",
        "  \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model target Path: /content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/output/iam/checkpoint_weights.pt\n",
            "source_path : /content/drive/MyDrive/Transformer_ocr_new/Transformer_ocr_beam/data/iam.hdf5\n",
            "time: 18.2 s (started: 2021-06-03 00:17:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db55DjBbJ24I"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNmSu47YHMA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0726c979-691a-46bc-9b28-23b145bacc0e"
      },
      "source": [
        "predicts"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A subomariner ' s wife needed to be spared as mud\",\n",
              " 'as possible . Anyloy the Parsilal affair was far',\n",
              " 'too fresh in both their minds tobe a comfortable',\n",
              " 'subject for discussion . \" Hs a command , \" he said . ',\n",
              " 'We can do with the ertra money . Jtll sist about',\n",
              " 'pay faculs sclool fees . \" what shall wedo',\n",
              " \"about this housel - and fill ' s saod ( and . ' \",\n",
              " 'how 3 hate the Nany ) ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.87 ms (started: 2021-06-03 00:17:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo_oCxxRDmQn"
      },
      "source": [
        "## Including Spell Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlTS2rlNS478",
        "outputId": "86f31703-d832-4a3a-e0bc-91c78d2bd7b9"
      },
      "source": [
        "%cd \"/content/drive/MyDrive/spelling-correction/src\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/spelling-correction/src\n",
            "time: 2.45 ms (started: 2021-06-03 00:18:17 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x0CBOrgULr9",
        "outputId": "a4114abe-7006-41d2-c262-65e7b945439f"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import string\n",
        "\n",
        "# define parameters\n",
        "source = \"iam\"\n",
        "mode = \"luong\"\n",
        "epochs = 1000\n",
        "batch_size = 64\n",
        "\n",
        "# define paths\n",
        "data_path = os.path.join(\"/content/drive/MyDrive/spelling-correction\", \"data\")\n",
        "source_path = os.path.join(data_path, f\"{source}.txt\")\n",
        "\n",
        "output_path = os.path.join(\"/content/drive/MyDrive/spelling-correction\", \"output\", source, mode)\n",
        "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# define number max of chars per line and list of valid chars\n",
        "max_text_length = 128\n",
        "charset_base = string.printable[:95]\n",
        "charset_special = \"\"\"ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã±Ã²Ã³Ã´ÃµÃ¶Ã¹ÃºÃ»Ã¼Ã½\"\"\"\n",
        "\n",
        "print(\"output\", output_path)\n",
        "print(\"target\", target_path)\n",
        "print(\"charset:\", charset_base + charset_special)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output /content/drive/MyDrive/spelling-correction/output/iam/luong\n",
            "target /content/drive/MyDrive/spelling-correction/output/iam/luong/checkpoint_weights.hdf5\n",
            "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã±Ã²Ã³Ã´ÃµÃ¶Ã¹ÃºÃ»Ã¼Ã½\n",
            "time: 692 ms (started: 2021-06-03 00:18:20 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPzQGHArUfkE",
        "outputId": "a8e12067-609c-4620-c719-9254212b4413"
      },
      "source": [
        "from data2.generator2 import DataGenerator as DataGenerator2\n",
        "\n",
        "dtgen = DataGenerator2(source=source_path,\n",
        "                      batch_size=64,\n",
        "                      charset=(charset_base + charset_special),\n",
        "                      max_text_length=128)\n",
        "\n",
        "print(f\"Train sentences: {dtgen.size['train']}\")\n",
        "print(f\"Validation sentences: {dtgen.size['valid']}\")\n",
        "print(f\"Test sentences: {dtgen.size['test']}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train sentences: 145314\n",
            "Validation sentences: 16145\n",
            "Test sentences: 32\n",
            "time: 7.38 s (started: 2021-06-03 00:18:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A5btp5wUUc-",
        "outputId": "aa7a4811-0c20-47b1-bd8a-f8f59dfe4446"
      },
      "source": [
        "from data2 import preproc as pp, evaluation as ev\n",
        "from tool.seq2seq import Seq2SeqAttention\n",
        "from tool.transformer import Transformer\n",
        "target_path ='/content/drive/MyDrive/spelling-correction/output/iam/luong/checkpoint_weights.hdf5'\n",
        "spell_check_model = Seq2SeqAttention(dtgen.tokenizer,\n",
        "                             mode,\n",
        "                             units=512,\n",
        "                             dropout=0.2,\n",
        "                             stop_tolerance=20,\n",
        "                             reduce_tolerance=15)\n",
        "\n",
        "spell_check_model.compile(learning_rate=0.001)\n",
        "#spell_check_model.summary(output_path, \"summary.txt\")\n",
        "\n",
        "# get default callbacks list and load checkpoint weights file (HDF5) if exists \n",
        "spell_check_model.load_checkpoint(target=target_path)\n",
        "\n",
        "callbacks = spell_check_model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 13.3 s (started: 2021-06-03 00:18:37 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cft7PL-CSzt",
        "outputId": "00aed1ac-937a-40dc-c306-3cd0e51b71d7"
      },
      "source": [
        "from data2 import preproc as pp\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 935 Âµs (started: 2021-06-03 00:19:45 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuHzy2uYBa7I",
        "outputId": "c8d24928-ba06-46a2-e6f7-89d7f4b142a9"
      },
      "source": [
        "input_list =predicts\n",
        "\n",
        "def next_test_batch(input_list):\n",
        "  inputs = dtgen.prepare_sequence(sentences=input_list, sos=True, eos=True)\n",
        "  yield [inputs]\n",
        "\n",
        "predicts_spell_correct = spell_check_model.predict(x = next_test_batch(input_list))\n",
        "predicts_spell_correct = [pp.text_standardize(x) for x in predicts_spell_correct]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 10.1 s (started: 2021-06-03 00:19:49 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbDVYdC_V15e",
        "outputId": "b83177d7-1e93-403a-bf5d-5a99d6c91f6a"
      },
      "source": [
        "predicts_spell_correct"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"A submariner ' s wife needed to be spared as much\",\n",
              " 'as possible . Anyway the Parsifal affair was far',\n",
              " 'too fresh in both their minds to be a comfortable',\n",
              " 'subject of discussion . \" He command , \" he said . \" Or .',\n",
              " 'We can do with the ertra money . All siti about',\n",
              " 'pay faculs closely . \" I shall we do',\n",
              " \"about this house - and fill ' s sard - and . '\",\n",
              " 'how that each , many -']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "stream",
          "text": [
            "time: 2.91 ms (started: 2021-06-03 00:20:08 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}